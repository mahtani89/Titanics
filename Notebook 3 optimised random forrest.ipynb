{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data is located /Users/deepakmahtani/.kaggle/competitions/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing to do is to import some standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lest read in the training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training=pd.read_csv('/Users/deepakmahtani/.kaggle/competitions/titanic/train.csv')\n",
    "raw_test=pd.read_csv('/Users/deepakmahtani/.kaggle/competitions/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After chatting with John the columns we are going to use are Survived, pclass, sex, age,SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_to_use=raw_training[['PassengerId', 'Survived', 'Pclass','Sex','Age','SibSp', 'Parch']]\n",
    "\n",
    "\n",
    "test_to_use=raw_test[['PassengerId', 'Pclass','Sex','Age','SibSp', 'Parch']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that the gender column is very important but we need to change this from male and female to a numeric value so lets change this in both the training and text set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "training_to_use.replace(to_replace='male', value=0, inplace=True)\n",
    "training_to_use.replace(to_replace='female', value=1, inplace=True)\n",
    "\n",
    "test_to_use.replace(to_replace='male', value=0, inplace=True)\n",
    "test_to_use.replace(to_replace='female', value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets replace the missing age values in the data with the median value. The reason we have chosen the median age and not the mean age is beacuse it is less affected by outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median age for the training set 28.0\n",
      "median age for the test set 27.0\n"
     ]
    }
   ],
   "source": [
    "median_age_training=np.median(training_to_use[pd.notnull(training_to_use['Age'])]['Age'])\n",
    "\n",
    "median_age_test=np.median(test_to_use[pd.notnull(test_to_use['Age'])]['Age'])\n",
    "\n",
    "print(\"median age for the training set\", median_age_training)\n",
    "print(\"median age for the test set\", median_age_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "clean_age_train=training_to_use['Age'].fillna(median_age_training)\n",
    "clean_age_test=test_to_use['Age'].fillna(median_age_test)\n",
    "\n",
    "training_to_use['clean_age']=clean_age_train\n",
    "test_to_use['clean_age']=clean_age_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets creat the two data frames to be used for the training and testing of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_training=training_to_use[['PassengerId','Survived', 'Pclass', 'Sex',\n",
    "                                     'SibSp', 'Parch','clean_age']]\n",
    "\n",
    "clean_data_test=test_to_use[['PassengerId', 'Pclass', 'Sex','SibSp', 'Parch', 'clean_age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train test split of the training set for the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid=clean_data_training[['Pclass', 'Sex','SibSp', 'Parch','clean_age']]\n",
    "y_grid=clean_data_training['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_grid, y_grid, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will initiate the random forrest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_classifier_grid_search=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "#n_estimators = [1,10,24,50]\n",
    "n_estimators = [10,15,20,24]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['sqrt','auto','log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [1,3,6,10,20,50]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2,4,10,20,50,100]\n",
    "min_samples_split = [2,4,10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [int(x) for x in np.linspace(2, 10, num = 8)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "search_params = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(forrest_classifier_grid_search, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 15, 20, 24], 'min_samples_split': [2, 4, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'bootstrap': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Params to use are {'bootstrap': True, 'min_samples_split': 30, 'n_estimators': 24}\n",
      "Which gives a best score on the training set of 0.8218298555377207\n"
     ]
    }
   ],
   "source": [
    "print('The best Params to use are', grid_search.best_params_ )\n",
    "\n",
    "print('Which gives a best score on the training set of',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 2, 'n_estimators': 24}\n",
    "\n",
    "The best Params to use are {'bootstrap': False, 'min_samples_split': 100, 'n_estimators':24}\n",
    "\n",
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 50, 'n_estimators':10}\n",
    "\n",
    "The best Params to use are {'bootstrap': False, 'min_samples_split': 50, 'n_estimators':24}\n",
    "\n",
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 10, 'n_estimators':10}\n",
    "\n",
    "it was jumping around a lot min sample split between 2-100 and n_estimators between 10 and 24 so narrowed down th range of these\n",
    "\n",
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 20, 'n_estimators': 10}<-going to go with this one\n",
    "\n",
    "Which gives a best score on the training set of 0.8218298555377207\n",
    "\n",
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 50, 'n_estimators': 24}\n",
    "Which gives a best score on the training set of 0.8138041733547352\n",
    "\n",
    "The best Params to use are {'bootstrap': True, 'min_samples_split': 30, 'n_estimators': 24}\n",
    "Which gives a best score on the training set of 0.8218298555377207\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now train a model using the best params and test using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_classifier_best_params=RandomForestClassifier(bootstrap=True,min_samples_split=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_classifier_best_params.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this gives a best score of 0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "print('this gives a best score of',forrest_classifier_best_params.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now lets see how well it does on the  real test set, first lets fit the model on all the training data with the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_classifier_test_data=RandomForestClassifier(bootstrap=True,min_samples_split=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=clean_data_training[['Pclass', 'Sex','SibSp', 'Parch','clean_age']]\n",
    "y=clean_data_training['Survived']\n",
    "\n",
    "\n",
    "forrest_classifier_test_data.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets creat the training data on which to make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=clean_data_test[['Pclass', 'Sex','SibSp', 'Parch','clean_age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets use the model to make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=forrest_classifier_test_data.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat a data frame to upload to kaggle to see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakmahtani/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "results=clean_data_test[['PassengerId']]\n",
    "results['Survived']=predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('random_forrest_optimised.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My previous modle gave me a score of 0.65071, and this model gave 0.64593 which was not better but this was when I ran it the first time I got best params of bootstrap=False, min_samples_split=50, n_estimators=10. When I did the grid search again I got best params of bootstrap = True, min_samples_split=50, n_estimators = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using bootstrap=True,min_samples_split=20,n_estimators=10 which gave 0.65071 which is equal with how good I did before so need to either use more features/do more feature engineering or try a different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
